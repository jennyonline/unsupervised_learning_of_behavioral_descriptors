{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.dummy\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import skvideo\n",
    "import skvideo.io\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "import torch\n",
    "from openTSNE import TSNE\n",
    "\n",
    "from unsupervised_behaviors.constants import DanceLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "device = \"cuda:1\"\n",
    "\n",
    "latents_path = \"/storage/mi/jennyonline/data/latents_videos.pt\"\n",
    "videos_path = \"/storage/mi/jennyonline/data/videos_2019_10000.h5\"\n",
    "model_path = \"/storage/mi/jennyonline/data/cpc_ben.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = torch.load(latents_path)\n",
    "\n",
    "with h5py.File(videos_path, \"r\") as f:\n",
    "    labels = f[\"labels\"][:]\n",
    "\n",
    "model, _, losses = torch.load(model_path)\n",
    "model = model.to(device)\n",
    "plt.plot(pd.Series(losses).rolling(128).mean())\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('/storage/mi/jennyonline/data/loss_cpc_ben.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = model.get_representations(\n",
    "    latents, batch_size, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = TSNE(n_jobs=-1).fit(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:, 0], embedding[:, 1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "colors = sns.color_palette(n_colors=len(DanceLabels))\n",
    "\n",
    "for label in DanceLabels:\n",
    "    elems = embedding[labels == label.value]\n",
    "    scatter = plt.scatter(elems[:, 0], elems[:, 1], s=3, c=[colors[label.value]], label=label.name)\n",
    "plt.title(\"very deep VAE -> CPC -> TSNE\")\n",
    "plt.legend()\n",
    "plt.xlabel('First t-SNE dimension')\n",
    "plt.ylabel('Second t-SNE dimension')\n",
    "plt.savefig('/storage/mi/jennyonline/data/t_sne.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = sklearn.linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000, n_jobs=4)\n",
    "sklearn.model_selection.cross_val_score(\n",
    "    linear,\n",
    "    latents.mean(axis=1),\n",
    "    labels,\n",
    "    cv=sklearn.model_selection.StratifiedShuffleSplit(),\n",
    "    scoring=sklearn.metrics.make_scorer(\n",
    "        sklearn.metrics.roc_auc_score, multi_class=\"ovo\", needs_proba=True\n",
    "    ),\n",
    "    n_jobs=-1,\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = sklearn.linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000, n_jobs=4)\n",
    "sklearn.model_selection.cross_val_score(\n",
    "    linear,\n",
    "    reps,\n",
    "    labels,\n",
    "    cv=sklearn.model_selection.StratifiedShuffleSplit(),\n",
    "    scoring=sklearn.metrics.make_scorer(\n",
    "        sklearn.metrics.roc_auc_score, multi_class=\"ovo\", needs_proba=True\n",
    "    ),\n",
    "    n_jobs=-1,\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.model_selection.cross_val_score(\n",
    "    sklearn.dummy.DummyClassifier(),\n",
    "    reps,\n",
    "    labels,\n",
    "    cv=sklearn.model_selection.StratifiedShuffleSplit(),\n",
    "    scoring=sklearn.metrics.make_scorer(\n",
    "        sklearn.metrics.roc_auc_score, multi_class=\"ovo\", needs_proba=True\n",
    "    ),\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array containing indices of labels that are 1 or 2 -> these indices are used for ami\n",
    "idx_for_ami = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i]==1):\n",
    "        idx_for_ami.append(i)\n",
    "    elif(labels[i]==2):\n",
    "        idx_for_ami.append(i)\n",
    "labels_for_ami = labels[idx_for_ami]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(reps)\n",
    "clusters_kmeans = np.array(kmeans.predict(reps))\n",
    "\n",
    "clusters_for_ami = clusters_kmeans[idx_for_ami]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami = sklearn.metrics.adjusted_mutual_info_score(labels_for_ami,clusters_for_ami)\n",
    "ami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kMeans on latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take frame in the middle for evaluation\n",
    "latents_for_clustering = latents[:,[16],:]\n",
    "latents_for_clustering = latents_for_clustering.reshape(10000,160)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(latents_for_clustering)\n",
    "clusters_kmeans_latents = np.array(kmeans.predict(latents_for_clustering))\n",
    "\n",
    "clusters_for_ami = clusters_kmeans_latents[idx_for_ami]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami = sklearn.metrics.adjusted_mutual_info_score(labels_for_ami,clusters_for_ami)\n",
    "ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take mean over all frames for evaluation\n",
    "latents_for_clustering = np.mean(latents, axis = 1)\n",
    "print(latents_for_clustering.shape)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(latents_for_clustering)\n",
    "clusters_kmeans_latents = np.array(kmeans.predict(latents_for_clustering))\n",
    "\n",
    "clusters_for_ami = clusters_kmeans_latents[idx_for_ami]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami = sklearn.metrics.adjusted_mutual_info_score(labels_for_ami,clusters_for_ami)\n",
    "ami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = sklearn.linear_model.LogisticRegression(multi_class=\"multinomial\", max_iter=1000, n_jobs=4)\n",
    "sklearn.model_selection.cross_val_score(\n",
    "    linear,\n",
    "    latents_for_clustering,\n",
    "    labels,\n",
    "    cv=sklearn.model_selection.StratifiedShuffleSplit(),\n",
    "    scoring=sklearn.metrics.make_scorer(\n",
    "        sklearn.metrics.roc_auc_score, multi_class=\"ovo\", needs_proba=True\n",
    "    ),\n",
    "    n_jobs=-1,\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kMeans using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=30,\n",
    "    random_state=42,\n",
    ").fit_transform(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(clusterable_embedding)\n",
    "clusters_kmeans_umap = np.array(kmeans.predict(clusterable_embedding))\n",
    "\n",
    "clusters_for_ami = clusters_kmeans_umap[idx_for_ami]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami = sklearn.metrics.adjusted_mutual_info_score(labels_for_ami,clusters_for_ami)\n",
    "ami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_hdb = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=200,\n",
    ").fit_predict(reps)\n",
    "\n",
    "clusters_for_ami = clusters_hdb[idx_for_ami]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami = sklearn.metrics.adjusted_mutual_info_score(labels_for_ami,clusters_for_ami)\n",
    "ami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDBSCAN using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_hdb_umap = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=200,\n",
    ").fit_predict(clusterable_embedding)\n",
    "\n",
    "clusters_for_ami = clusters_hdb_umap[idx_for_ami]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami = sklearn.metrics.adjusted_mutual_info_score(labels_for_ami,clusters_for_ami)\n",
    "ami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choosing and creating videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_zero = []\n",
    "clusters_one = []\n",
    "clusters_two = []\n",
    "\n",
    "for i in range(len(clusters_kmeans)):\n",
    "    if(clusters_kmeans[i]==0):\n",
    "        clusters_zero.append(i)\n",
    "    elif(clusters_kmeans[i]==1):\n",
    "        clusters_one.append(i)\n",
    "    else:\n",
    "        clusters_two.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video(\n",
    "    h5_path: pathlib.Path, video_idx: int, output_path: pathlib.Path, with_mask: bool = False\n",
    "):\n",
    "    \"\"\"Extract a single video from the h5 file and store it in a compressed video.\n",
    "    Parameters\n",
    "    ----------\n",
    "    h5_path: pathlib.Path\n",
    "        Video h5 file path.\n",
    "    video_idx: int\n",
    "        Sequential index of video to extract.\n",
    "    output_path: pathlib.Path\n",
    "        Output video path.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "\n",
    "        video = f[\"images\"][video_idx]\n",
    "\n",
    "        if with_mask:\n",
    "            mask = f[\"tag_masks\"][video_idx] * f[\"loss_masks\"][video_idx]\n",
    "            video *= mask\n",
    "\n",
    "        outputdict = {\"-c:v\": \"libx264\", \"-crf\": \"0\", \"-preset\": \"veryslow\", \"-filter:v\": \"fps=6\"}\n",
    "\n",
    "        with skvideo.io.FFmpegWriter(output_path, outputdict=outputdict) as writer:\n",
    "            for frame in video:\n",
    "                writer.writeFrame(frame[:, :, None].repeat(3, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    path_zero = '/storage/mi/jennyonline/videos/videos1_zero_' + str(i) + '.mp4'\n",
    "    extract_video(videos_path, clusters_zero[i], path_zero)\n",
    "    path_one = '/storage/mi/jennyonline/videos/videos1_one_' + str(i) + '.mp4'\n",
    "    extract_video(videos_path, clusters_one[i], path_one)\n",
    "    path_two = '/storage/mi/jennyonline/videos/videos1_two_' + str(i) + '.mp4'\n",
    "    extract_video(videos_path, clusters_two[i], path_two)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
