{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import skimage.exposure\n",
    "import sklearn.manifold\n",
    "\n",
    "import deepVAEHelpers.hps as hps\n",
    "from deepVAEHelpers.train_helpers import set_up_hyperparams, load_opt\n",
    "from deepVAEHelpers.vae import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ set up vae model in order to get latents #############\n",
    "\n",
    "# set hyperparameter\n",
    "H = set_up_hyperparams(s=[\"--dataset=i64\"])\n",
    "H_ = hps.ffhq_256\n",
    "H_[\"image_channels\"] = 1\n",
    "H_[\"image_size\"] = 128\n",
    "H_[\"width\"] = 128\n",
    "H_[\"n_batch\"] = 2\n",
    "H_.dec_blocks = \"1x2,4m1,4x3,8m4,8x4,16m8,16x9,32m16,32x20,64m32,64x12,128m64\"\n",
    "H_.enc_blocks = \"128x4,128d2,64x7,64d2,32x7,32d2,16x7,16d2,8x7,8d2,4x7,4d4,1x8\"\n",
    "H_[\"adam_warmup_iters\"] = 100\n",
    "H.update(H_)\n",
    "H.lr = 0.0001\n",
    "H.num_epochs = 1\n",
    "H[\"skip_threshold\"] = -1\n",
    "\n",
    "with h5py.File('/storage/mi/jennyonline/data/data_2020_100000_unbiased.h5', 'r') as f:\n",
    "    sample_image = f['images'][:8].astype(np.float32)\n",
    "    sample_mask = f['tag_masks'][:8].astype(np.float32)\n",
    "    sample_loss_mask = f['loss_masks'][:8].astype(np.float32)\n",
    "    H[\"std\"] = f['std'][()]\n",
    "    std = H[\"std\"]\n",
    "    H[\"mean\"] = f['mean'][()]\n",
    "    mean = H[\"mean\"]\n",
    "\n",
    "# load model\n",
    "vae = VAE(H).to(device)\n",
    "vae.load_state_dict(torch.load(\"/storage/mi/jennyonline/data/vae_supervised.pt\"))\n",
    "_ = vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/storage/mi/jennyonline/data/data_2020_100000_unbiased.h5', 'r')\n",
    "\n",
    "images = f['images']\n",
    "tag_masks = f['tag_masks']\n",
    "loss_masks = f['loss_masks']\n",
    "labels = f['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_deformed = np.argwhere(labels).flatten()\n",
    "images_deformed = images[idxs_deformed]\n",
    "tag_masks_deformed = tag_masks[idxs_deformed]\n",
    "\n",
    "idxs_normal = np.argwhere(~labels[:]).flatten()\n",
    "images_normal = images[idxs_normal]\n",
    "tag_masks_normal = tag_masks[idxs_normal]\n",
    "\n",
    "print(images_deformed.shape, images_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latents_batch(images, tag_mask, latent_dimensions=None):\n",
    "    with torch.no_grad():\n",
    "        x = torch.from_numpy(images.astype(np.float32))[:, :, :, None]\n",
    "\n",
    "        x -= H[\"mean\"]\n",
    "        x /= H[\"std\"]\n",
    "        x = x.to(device)\n",
    "\n",
    "        tag_mask = torch.from_numpy(tag_mask.astype(np.float32))[:, :, :, None].to(device)\n",
    "        data_input = (x * tag_mask).float()\n",
    "        target = data_input.clone().detach()\n",
    "\n",
    "        stats = vae.forward_get_latents(data_input)\n",
    "        \n",
    "        zs = []\n",
    "        \n",
    "        if latent_dimensions is None:\n",
    "            latent_dimensions = np.arange(len(stats))\n",
    "        \n",
    "        for dim in latent_dimensions:\n",
    "            z = stats[dim]['qm'].cpu().numpy()\n",
    "\n",
    "            if z.shape[-1] == 1:\n",
    "                zs.append(z[:, :, 0, 0])\n",
    "            else:\n",
    "                zs.append(z.mean(axis=(2, 3)))\n",
    "                \n",
    "        return np.concatenate(zs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latents(images, tag_masks, batch_size=8, num_dimensions=1):\n",
    "    zs = []\n",
    "    i = 0\n",
    "    while sum(map(len, zs)) < len(images):\n",
    "        with torch.no_grad():\n",
    "            idxer = slice(i, min(len(images), i + batch_size))\n",
    "            zs.append(get_latents_batch(images[idxer], tag_masks[idxer], latent_dimensions=np.arange(num_dimensions)))\n",
    "\n",
    "            sys.stdout.write(f'\\r{i}/{len(images)}')\n",
    "            i += batch_size\n",
    "\n",
    "    zs = np.concatenate(zs)\n",
    "    return zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_deformed = get_latents(images_deformed, tag_masks_deformed)\n",
    "labels_deformed = np.ones(len(latents_deformed))\n",
    "latents_normal = get_latents(images_normal, tag_masks_normal)\n",
    "labels_normal = np.zeros(len(latents_normal))\n",
    "\n",
    "latents = np.concatenate((latents_deformed, latents_normal))\n",
    "labels = np.concatenate((labels_deformed, labels_normal))\n",
    "images_samples = np.concatenate((images_deformed, images_normal))\n",
    "tag_masks_samples = np.concatenate((tag_masks_deformed, tag_masks_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score\n",
    "linear = sklearn.linear_model.LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "\n",
    "sklearn.model_selection.cross_val_score(\n",
    "    linear, \n",
    "    latents, \n",
    "    labels, \n",
    "    cv=sklearn.model_selection.StratifiedShuffleSplit(), \n",
    "    scoring=sklearn.metrics.make_scorer(sklearn.metrics.roc_auc_score, needs_proba=True)\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy f\n",
    "(linear.fit(latents, labels).predict(latents) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = sklearn.model_selection.StratifiedShuffleSplit()\n",
    "\n",
    "X = latents\n",
    "y = labels\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    linear = sklearn.linear_model.LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "    linear.fit(X[train], y[train])\n",
    "    viz = sklearn.metrics.plot_roc_curve(linear, X[test], y[test],\n",
    "                         name='ROC fold {}'.format(i),\n",
    "                         alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = sklearn.metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic\")\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.savefig(\"/storage/mi/jennyonline/new_images/roc.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear.fit(X, y)\n",
    "yp = linear.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(16, 16))\n",
    "\n",
    "for i in range(5 * 5):\n",
    "    idx = np.argsort(yp)[::-1][i]\n",
    "    r, c = divmod(i, 5)\n",
    "    axes[r, c].imshow(images_samples[idx], cmap=plt.cm.gray, vmin=0, vmax=255)\n",
    "    axes[r, c].set_title(f'label={bool(labels[idx])} | p={yp[idx]:.2f}')\n",
    "    axes[r, c].axis('off')\n",
    "    \n",
    "fig.suptitle('Samples with highest probability for deformed wings', fontsize=16, y=1.01)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(16, 16))\n",
    "\n",
    "for i in range(5 * 5):\n",
    "    idx = np.argsort(yp)[i]\n",
    "    r, c = divmod(i, 5)\n",
    "    axes[r, c].imshow(images_samples[idx], cmap=plt.cm.gray, vmin=0, vmax=255)\n",
    "    axes[r, c].set_title(f'label={bool(labels[idx])} | p={yp[idx]:.2f}')\n",
    "    axes[r, c].axis('off')\n",
    "    \n",
    "fig.suptitle('Samples with lowest probability for deformed wings', fontsize=16, y=1.01)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(16, 16))\n",
    "\n",
    "for i in range(5 * 5):\n",
    "    idx = np.argsort(np.abs(yp - 0.5))[i]\n",
    "    r, c = divmod(i, 5)\n",
    "    axes[r, c].imshow(images_samples[idx], cmap=plt.cm.gray, vmin=0, vmax=255)\n",
    "    axes[r, c].set_title(f'label={bool(labels[idx])} | p={yp[idx]:.2f}')\n",
    "    axes[r, c].axis('off')\n",
    "    \n",
    "fig.suptitle('Samples with highest uncertainty for deformed wings', fontsize=16, y=1.01)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null hypothesis: Main contributing factor is image brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = images_samples.mean(axis=(1, 2))[:, None]\n",
    "\n",
    "plt.scatter(\n",
    "    yp,\n",
    "    Xi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = sklearn.linear_model.LogisticRegression(class_weight='balanced')\n",
    "\n",
    "sklearn.model_selection.cross_val_score(\n",
    "    linear, \n",
    "    Xi,\n",
    "    labels, \n",
    "    cv=sklearn.model_selection.StratifiedShuffleSplit(), \n",
    "    scoring=sklearn.metrics.make_scorer(sklearn.metrics.roc_auc_score, needs_proba=True)\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(linear.fit(Xi, labels).predict(Xi) == labels).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
