{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically update imports when they are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm.auto as tqdm\n",
    "import imageio\n",
    "import io\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "import hierarchical_vae.hps as hps\n",
    "from hierarchical_vae.train_helpers import set_up_hyperparams, load_opt\n",
    "from hierarchical_vae.vae import VAE\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purposes 'testing' can be set to true, than the model is ran on only 'nr_images' many images\n",
    "testing = False\n",
    "nr_images = 10\n",
    "\n",
    "# only for use on images, not on sequences\n",
    "f = h5py.File('/storage/mi/jennyonline/data/data_2020_100000_unbiased.h5', 'r')\n",
    "\n",
    "images = f['images']\n",
    "tag_masks = f['tag_masks']\n",
    "loss_masks = f['loss_masks']\n",
    "labels = f['labels']\n",
    "\n",
    "if(testing):\n",
    "    images = f['images'][:nr_images]\n",
    "    tag_masks = f['tag_masks'][:nr_images]\n",
    "    loss_masks = f['loss_masks'][:nr_images]\n",
    "    labels = f['labels'][:nr_images]\n",
    "\n",
    "mean = f['mean'][()]\n",
    "std = f['std'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# print an image and its masked representation ###############\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].imshow(images[0], cmap=plt.cm.gray)\n",
    "axes[1].imshow(images[0] * loss_masks[0], cmap=plt.cm.gray)\n",
    "axes[2].imshow(images[0] * loss_masks[0] * tag_masks[0], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# set hyperparameter for model ###############\n",
    "\n",
    "H = set_up_hyperparams(s=[\"--dataset=i64\"])\n",
    "H_ = hps.ffhq_256\n",
    "H_[\"image_channels\"] = 1\n",
    "H_[\"image_size\"] = 128\n",
    "H_[\"width\"] = 128\n",
    "H_[\"n_batch\"] = 8\n",
    "H_.dec_blocks = \"1x2,4m1,4x3,8m4,8x4,16m8,16x9,32m16,32x20,64m32,64x12,128m64\"\n",
    "H_.enc_blocks = \"128x4,128d2,64x7,64d2,32x7,32d2,16x7,16d2,8x7,8d2,4x7,4d4,1x8\"\n",
    "H_[\"adam_warmup_iters\"] = 100\n",
    "H.update(H_)\n",
    "H[\"skip_threshold\"] = -1\n",
    "\n",
    "H[\"std\"] = std\n",
    "H[\"mean\"] = mean\n",
    "\n",
    "H.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(H).to(device)\n",
    "optimizer, scheduler, cur_eval_loss, iterate, starting_epoch = load_opt(H, vae)\n",
    "\n",
    "elbos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = sklearn.linear_model.SGDRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# train ###############\n",
    "H.num_epochs = 20\n",
    "eval_dimension = 0\n",
    "\n",
    "# coefficient for supervised and unsupervised objective function to control ratio between these two\n",
    "coefficient = 0.5\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for i_epoch in range(H.num_epochs):\n",
    "    progress = tqdm.trange(len(images) // H_['n_batch'])\n",
    "        \n",
    "    # for every batch\n",
    "    for i in progress:\n",
    "        random_idxs = sorted(np.random.choice(np.arange(len(images)), H_['n_batch'], replace=False))\n",
    "                \n",
    "        x = torch.from_numpy(images[random_idxs][:, :, :, None].astype(np.float32))\n",
    "        x -= H[\"mean\"]\n",
    "        x /= H[\"std\"]\n",
    "        x = x.to(device)\n",
    "        \n",
    "        labels = f['labels'][random_idxs]\n",
    "        \n",
    "        target_mask = torch.from_numpy(loss_masks[random_idxs][:, :, :, None]).to(device)\n",
    "        tag_mask = torch.from_numpy(tag_masks[random_idxs][:, :, :, None]).to(device)\n",
    "        data_input = (x * tag_mask).float()\n",
    "        target = data_input.clone().detach()\n",
    "        \n",
    "        vae.zero_grad()\n",
    "        stats = vae.forward(data_input, target, target_mask * tag_mask)\n",
    "        \n",
    "        # logistic regression for supervised part\n",
    "        # compute f1 score and add value to elbo with a coefficient defining the ratio\n",
    "        with torch.no_grad():\n",
    "            stats_with_latents = vae.forward_get_latents(data_input)\n",
    "        \n",
    "            z = stats_with_latents[eval_dimension]['z'].cpu().numpy()\n",
    "        \n",
    "            if z.shape[-1] == 1:\n",
    "                z = z[:, :, 0, 0]\n",
    "            else:\n",
    "                z = z.mean(axis=(2, 3))\n",
    "        \n",
    "        regression.partial_fit(z, labels, sample_weight=None)\n",
    "        loss = regression.score(z,labels)\n",
    "        \n",
    "        complete_loss = (1-coefficient)*stats[\"elbo\"] + coefficient*loss\n",
    "        complete_loss.backward()\n",
    "        \n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(vae.parameters(), H.grad_clip).item()\n",
    "        \n",
    "        distortion_nans = torch.isnan(stats[\"distortion\"]).sum()\n",
    "        rate_nans = torch.isnan(stats[\"rate\"]).sum()\n",
    "        \n",
    "        stats.update(\n",
    "            dict(\n",
    "                rate_nans=0 if rate_nans == 0 else 1,\n",
    "                distortion_nans=0 if distortion_nans == 0 else 1,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        elbos.append(stats[\"elbo\"].item())\n",
    "        \n",
    "        # only do an update step if no rank has a NaN and if the grad norm is below a specific threshold\n",
    "        if (\n",
    "            stats[\"distortion_nans\"] == 0\n",
    "            and stats[\"rate_nans\"] == 0\n",
    "            and (H.skip_threshold == -1 or grad_norm < H.skip_threshold)\n",
    "        ):\n",
    "            optimizer.step()\n",
    "            skipped_updates = 0\n",
    "\n",
    "            progress.set_postfix(\n",
    "                dict(\n",
    "                    ELBO=np.nanmean(elbos[-100:]),\n",
    "                    lr=scheduler.get_last_lr()[0],\n",
    "                    has_nan=np.any(np.isnan(elbos[-100:])),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            scheduler.step()\n",
    "    \n",
    "    print(\"Epoch \", i_epoch, \" is over\")\n",
    "    store_at = \"/storage/mi/jennyonline/data/vae_supervised_\" + str(i_epoch) + \".pt\"\n",
    "    torch.save(vae.state_dict(), store_at)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime: \", ((end - start)/60), \" Minuten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(),\"/storage/mi/jennyonline/data/vae_supervised.pt\")   \n",
    "np.savez('trash/elbos_supervised', elbos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae = VAE(H).to(device)\n",
    "# vae.load_state_dict(torch.load(\"/storage/mi/jennyonline/supervisedVAE_23_08/vae_supervised.pt\"))\n",
    "# _ = vae.eval()\n",
    "\n",
    "# elbos = np.load(\"/storage/mi/jennyonline/supervisedVAE_23_08/elbos_supervised.npz\")\n",
    "# elbos = elbos.f.arr_0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elbo = pd.Series(elbos).rolling(1024, min_periods=200).mean()\n",
    "plot_elbo.plot()\n",
    "plt.savefig('/storage/mi/jennyonline/supervisedVAE_23_08/elbos_supervised_1024_200.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### get latents of images out of saved model and print images ####################\n",
    "\n",
    "vae.cpu()\n",
    "vae.eval()\n",
    "\n",
    "# choose one image from first batch for plotting -> here first image of batch is chosen\n",
    "sample_idx = 0\n",
    "temperature = .2\n",
    "min_kl = 0\n",
    "\n",
    "x = torch.from_numpy(images[:H['n_batch']].astype(np.float32))[:, :, :, None]\n",
    "x -= mean\n",
    "x /= std\n",
    "\n",
    "tag_mask = torch.from_numpy(tag_masks[0].astype(np.float32))[None, :, :, None]\n",
    "mask = (loss_masks[0] * tag_masks[0]).astype(np.float32)\n",
    "data_input = (x * tag_mask).float()\n",
    "\n",
    "fig, axes = plt.subplots(1, 7, figsize=(20, 8))\n",
    "\n",
    "axes[0].imshow(\n",
    "    ((data_input[sample_idx].data.numpy() * std) + mean)[:, :, 0],\n",
    "    cmap=plt.cm.gray,\n",
    ")\n",
    "\n",
    "minv = ((data_input[sample_idx].data.numpy() * std) + mean)[:, :, 0].min()\n",
    "maxv = ((data_input[sample_idx].data.numpy() * std) + mean)[:, :, 0].max()\n",
    "\n",
    "with io.BytesIO() as f:\n",
    "    imageio.imsave(f, ((data_input[sample_idx] * std) + mean).data.numpy().astype(np.uint8), format='png')\n",
    "    f.flush()\n",
    "    f.seek(0)\n",
    "    bytes_png = len(f.read())\n",
    "\n",
    "axes[0].set_title(f\"$x$ - {bytes_png / 1024:.3f}KiB (PNG)\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    zs = [s[\"z\"] for s in vae.forward_get_latents(data_input)]\n",
    "    kls = [s[\"kl\"] for s in vae.forward_get_latents(data_input)]\n",
    "    \n",
    "    for z, k in zip(zs, kls):\n",
    "        z[k < min_kl] = 0\n",
    "        k[k < min_kl] = 0\n",
    "    \n",
    "    qms = [s[\"qm\"] for s in vae.forward_get_latents(data_input)]\n",
    "    qvs = [s[\"qv\"] for s in vae.forward_get_latents(data_input)]\n",
    "    \n",
    "    mb = data_input.shape[0]\n",
    "      \n",
    "def plot_layer(ax, layer_idx):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        px_z = vae.decoder.forward_manual_latents(mb, zs[:layer_idx], t=temperature)\n",
    "        \n",
    "        samples = vae.decoder.out_net.sample(px_z)\n",
    "        \n",
    "        ax.imshow(samples[sample_idx, :, :, 0] * mask + (1 - mask) * mean, cmap=plt.cm.gray, vmin=minv, vmax=maxv)\n",
    "        \n",
    "        all_kls = np.concatenate([k[0].cpu().data.numpy().flatten() for k in kls[:layer_idx]])\n",
    "        \n",
    "        ax.set_title(f\"$z_{{{layer_idx}}}$ - {(all_kls / np.log(2)).sum() / 8 / 1024:.3f}KiB\")\n",
    "\n",
    "for ax, layer_idx in zip(axes[1:], (2, 6, 12, 20, 36, len(zs)+1)):\n",
    "    plot_layer(ax, layer_idx)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# sample images from latent space ###############\n",
    "\n",
    "sample_idx = 1\n",
    "temperature = 0.5\n",
    "\n",
    "fig, axes = plt.subplots(4, 6, figsize=(12, 8))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for r in range(4):\n",
    "        for c in range(6):\n",
    "            mb = data_input.shape[0]\n",
    "            px_z = vae.decoder.forward_uncond(mb, t=temperature)\n",
    "            samples = vae.decoder.out_net.sample(px_z)\n",
    "            axes[r, c].imshow(samples[sample_idx, :, :, 0], cmap=plt.cm.gray)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "for ax in axes.flatten():\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save([tuple(H.items()), vae.state_dict()], open(\"models/vdvae64_lossmasked.pt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kls = np.concatenate([k[0].cpu().data.numpy().flatten() for k in kls])\n",
    "# blue\n",
    "plt.hist(all_kls, log=True)\n",
    "# orange\n",
    "plt.hist(all_kls, bins=25, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qms = np.concatenate([k[0].cpu().data.numpy().flatten() for k in qms[:12]])\n",
    "plt.hist(all_qms, log=True, bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_df = []\n",
    "layer_bytes = []\n",
    "\n",
    "for layer_idx, layer_kl in enumerate(kls):\n",
    "    layer_df = pd.DataFrame(list(layer_kl.mean(dim=(0, 2, 3)).cpu().data.numpy()), columns=['KL'])\n",
    "    layer_df['layer'] = layer_idx\n",
    "    kl_df.append(layer_df)\n",
    "    layer_bytes.append((layer_kl[0] / np.log(2)).sum().item() / 8)\n",
    "    \n",
    "kl_df = pd.concat(kl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "sns.swarmplot(x='layer', y='KL', data=kl_df, color='gray', s=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(layer_bytes)\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Entropy in bytes')\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_df.groupby('layer').mean().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
